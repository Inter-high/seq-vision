{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ==============================\n",
    "# 1. 폴더로부터 .avi 파일들 읽어오기\n",
    "# ==============================\n",
    "folder = \"/workspace/seq-vision/UCF101\"\n",
    "files = [f for f in os.listdir(folder) if f.lower().endswith('.avi') and os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "# ==============================\n",
    "# 2. 파일명에서 1번째 '_'와 2번째 '_' 사이의 문자열을 추출하여\n",
    "#    label로 사용 (원래 문자열이므로 unique하게 모은 후 정렬하여 0~100 할당, 총 101개여야 함)\n",
    "# ==============================\n",
    "# key: label(string), value: 파일 경로 리스트\n",
    "class_to_files = {}\n",
    "for file in files:\n",
    "    filename = os.path.splitext(file)[0]\n",
    "    first_us = filename.find('_')\n",
    "    if first_us == -1:\n",
    "        print(f\"파일 '{file}'에 '_'가 없습니다. 건너뜁니다.\")\n",
    "        continue\n",
    "    second_us = filename.find('_', first_us + 1)\n",
    "    if second_us == -1:\n",
    "        print(f\"파일 '{file}'에 두 번째 '_'가 없습니다. 건너뜁니다.\")\n",
    "        continue\n",
    "    # 1번째 '_'와 2번째 '_' 사이의 문자열 추출 (문자열 label)\n",
    "    label_str = filename[first_us+1:second_us]\n",
    "    class_to_files.setdefault(label_str, []).append(os.path.join(folder, file))\n",
    "\n",
    "# 고유 label들을 추출하여 정렬 (반드시 101개여야 함)\n",
    "unique_labels = sorted(class_to_files.keys())\n",
    "if len(unique_labels) != 101:\n",
    "    print(f\"경고: 고유 label의 개수가 101개가 아닙니다. (총 {len(unique_labels)}개)\")\n",
    "global_label2idx = { label: idx for idx, label in enumerate(unique_labels) }\n",
    "print(\"생성된 label mapping (문자열 -> 정수):\")\n",
    "for label, idx in global_label2idx.items():\n",
    "    print(f\"'{label}' -> {idx}\")\n",
    "\n",
    "# ==============================\n",
    "# 3. 각 클래스마다 10개 샘플 채취 (각 비디오는 75프레임, 부족 시 제로 패딩)\n",
    "# ==============================\n",
    "target_frames = 75\n",
    "class_to_videos = {}\n",
    "for label_str, file_list in class_to_files.items():\n",
    "    if len(file_list) < 10:\n",
    "        print(f\"클래스 '{label_str}'의 파일 개수가 10개 미만입니다 (총 {len(file_list)}개). 건너뜁니다.\")\n",
    "        continue\n",
    "    # 10개보다 많으면 랜덤 샘플링\n",
    "    selected_files = random.sample(file_list, 10) if len(file_list) > 10 else file_list\n",
    "    videos = []\n",
    "    for video_path in selected_files:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"영상 '{video_path}' 열기 실패. 건너뜁니다.\")\n",
    "            continue\n",
    "        frames = []\n",
    "        # 최대 target_frames 만큼 프레임 읽기\n",
    "        for _ in range(target_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        if len(frames) == 0:\n",
    "            print(f\"영상 '{video_path}'에서 프레임을 하나도 읽지 못했습니다.\")\n",
    "            continue\n",
    "        # 75프레임 미만이면 제로 패딩 (첫 프레임과 동일한 shape 사용)\n",
    "        if len(frames) < target_frames:\n",
    "            pad_frame = np.zeros_like(frames[0])\n",
    "            for _ in range(target_frames - len(frames)):\n",
    "                frames.append(pad_frame)\n",
    "        # 75프레임 초과 시 처음 75프레임만 사용\n",
    "        if len(frames) > target_frames:\n",
    "            frames = frames[:target_frames]\n",
    "        videos.append(frames)\n",
    "    if len(videos) != 10:\n",
    "        print(f\"클래스 '{label_str}'의 10개 샘플을 모으지 못했습니다. (모은 샘플 수: {len(videos)})\")\n",
    "        continue\n",
    "    class_to_videos[label_str] = videos\n",
    "\n",
    "# ==============================\n",
    "# 4. 각 클래스의 10개 샘플을 (6, 2, 2) 비율로 train, valid, test 분할\n",
    "# ==============================\n",
    "train_list = []\n",
    "valid_list = []\n",
    "test_list = []\n",
    "for label_str, videos in class_to_videos.items():\n",
    "    random.shuffle(videos)\n",
    "    train_videos = videos[:6]\n",
    "    valid_videos = videos[6:8]\n",
    "    test_videos  = videos[8:10]\n",
    "    for video in train_videos:\n",
    "        train_list.append((label_str, video))\n",
    "    for video in valid_videos:\n",
    "        valid_list.append((label_str, video))\n",
    "    for video in test_videos:\n",
    "        test_list.append((label_str, video))\n",
    "\n",
    "# ==============================\n",
    "# 5. PyTorch Dataset 및 DataLoader 생성\n",
    "#    - 각 영상은 프레임 리스트를 torch tensor로 변환 (shape: [num_frames, C, H, W])\n",
    "#    - transform을 통해 모든 프레임을 (224, 224)로 리사이즈\n",
    "#    - label은 global_label2idx를 사용하여 (1,) shape의 tensor로 반환\n",
    "# ==============================\n",
    "def resize_video_frames(video_tensor, size=(224, 224)):\n",
    "    # video_tensor: (num_frames, C, H, W)\n",
    "    return F.interpolate(video_tensor, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_list, label2idx, transform=None):\n",
    "        \"\"\"\n",
    "        video_list: 각 항목이 (label_str, frames(list)) 형태\n",
    "        label2idx: 전역 label mapping (문자열 -> 정수)\n",
    "        transform: 영상 텐서에 적용할 함수. 기본적으로 모든 프레임을 (224,224)로 리사이즈함.\n",
    "        \"\"\"\n",
    "        self.video_list = video_list\n",
    "        self.label2idx = label2idx\n",
    "        self.transform = transform if transform is not None else lambda video: resize_video_frames(video, size=(224, 224))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_str, frames = self.video_list[idx]\n",
    "        # 각 프레임: numpy array (H, W, C) -> torch tensor (C, H, W)\n",
    "        video_tensor = torch.stack([torch.from_numpy(frame).permute(2, 0, 1) for frame in frames])\n",
    "        if self.transform:\n",
    "            video_tensor = self.transform(video_tensor)\n",
    "        # label은 global_label2idx를 통해 정수로 변환, (1,) shape의 tensor 반환\n",
    "        label_tensor = torch.tensor([self.label2idx[label_str]], dtype=torch.long)\n",
    "        return video_tensor, label_tensor\n",
    "\n",
    "# Dataset 생성\n",
    "train_dataset = VideoDataset(train_list, label2idx=global_label2idx)\n",
    "valid_dataset = VideoDataset(valid_list, label2idx=global_label2idx)\n",
    "test_dataset  = VideoDataset(test_list,  label2idx=global_label2idx)\n",
    "\n",
    "# DataLoader 생성 (배치 사이즈는 4로 설정)\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVI 파일들을 로드하는 중...\n",
      "총 13320개의 AVI 파일이 발견되었습니다.\n",
      "파일들을 label 기준으로 그룹화하는 중...\n",
      "label mapping 생성 중...\n",
      "생성된 label mapping (문자열 -> 정수):\n",
      "'ApplyEyeMakeup' -> 0\n",
      "'ApplyLipstick' -> 1\n",
      "'Archery' -> 2\n",
      "'BabyCrawling' -> 3\n",
      "'BalanceBeam' -> 4\n",
      "'BandMarching' -> 5\n",
      "'BaseballPitch' -> 6\n",
      "'Basketball' -> 7\n",
      "'BasketballDunk' -> 8\n",
      "'BenchPress' -> 9\n",
      "'Biking' -> 10\n",
      "'Billiards' -> 11\n",
      "'BlowDryHair' -> 12\n",
      "'BlowingCandles' -> 13\n",
      "'BodyWeightSquats' -> 14\n",
      "'Bowling' -> 15\n",
      "'BoxingPunchingBag' -> 16\n",
      "'BoxingSpeedBag' -> 17\n",
      "'BreastStroke' -> 18\n",
      "'BrushingTeeth' -> 19\n",
      "'CleanAndJerk' -> 20\n",
      "'CliffDiving' -> 21\n",
      "'CricketBowling' -> 22\n",
      "'CricketShot' -> 23\n",
      "'CuttingInKitchen' -> 24\n",
      "'Diving' -> 25\n",
      "'Drumming' -> 26\n",
      "'Fencing' -> 27\n",
      "'FieldHockeyPenalty' -> 28\n",
      "'FloorGymnastics' -> 29\n",
      "'FrisbeeCatch' -> 30\n",
      "'FrontCrawl' -> 31\n",
      "'GolfSwing' -> 32\n",
      "'Haircut' -> 33\n",
      "'HammerThrow' -> 34\n",
      "'Hammering' -> 35\n",
      "'HandStandPushups' -> 36\n",
      "'HandstandWalking' -> 37\n",
      "'HeadMassage' -> 38\n",
      "'HighJump' -> 39\n",
      "'HorseRace' -> 40\n",
      "'HorseRiding' -> 41\n",
      "'HulaHoop' -> 42\n",
      "'IceDancing' -> 43\n",
      "'JavelinThrow' -> 44\n",
      "'JugglingBalls' -> 45\n",
      "'JumpRope' -> 46\n",
      "'JumpingJack' -> 47\n",
      "'Kayaking' -> 48\n",
      "'Knitting' -> 49\n",
      "'LongJump' -> 50\n",
      "'Lunges' -> 51\n",
      "'MilitaryParade' -> 52\n",
      "'Mixing' -> 53\n",
      "'MoppingFloor' -> 54\n",
      "'Nunchucks' -> 55\n",
      "'ParallelBars' -> 56\n",
      "'PizzaTossing' -> 57\n",
      "'PlayingCello' -> 58\n",
      "'PlayingDaf' -> 59\n",
      "'PlayingDhol' -> 60\n",
      "'PlayingFlute' -> 61\n",
      "'PlayingGuitar' -> 62\n",
      "'PlayingPiano' -> 63\n",
      "'PlayingSitar' -> 64\n",
      "'PlayingTabla' -> 65\n",
      "'PlayingViolin' -> 66\n",
      "'PoleVault' -> 67\n",
      "'PommelHorse' -> 68\n",
      "'PullUps' -> 69\n",
      "'Punch' -> 70\n",
      "'PushUps' -> 71\n",
      "'Rafting' -> 72\n",
      "'RockClimbingIndoor' -> 73\n",
      "'RopeClimbing' -> 74\n",
      "'Rowing' -> 75\n",
      "'SalsaSpin' -> 76\n",
      "'ShavingBeard' -> 77\n",
      "'Shotput' -> 78\n",
      "'SkateBoarding' -> 79\n",
      "'Skiing' -> 80\n",
      "'Skijet' -> 81\n",
      "'SkyDiving' -> 82\n",
      "'SoccerJuggling' -> 83\n",
      "'SoccerPenalty' -> 84\n",
      "'StillRings' -> 85\n",
      "'SumoWrestling' -> 86\n",
      "'Surfing' -> 87\n",
      "'Swing' -> 88\n",
      "'TableTennisShot' -> 89\n",
      "'TaiChi' -> 90\n",
      "'TennisSwing' -> 91\n",
      "'ThrowDiscus' -> 92\n",
      "'TrampolineJumping' -> 93\n",
      "'Typing' -> 94\n",
      "'UnevenBars' -> 95\n",
      "'VolleyballSpiking' -> 96\n",
      "'WalkingWithDog' -> 97\n",
      "'WallPushups' -> 98\n",
      "'WritingOnBoard' -> 99\n",
      "'YoYo' -> 100\n",
      "각 클래스별로 비디오 샘플 채취 중...\n",
      "비디오 데이터를 train, valid, test로 분할하는 중...\n",
      "Train samples: 606, Valid samples: 202, Test samples: 202\n",
      "PyTorch Dataset 및 DataLoader 생성 중...\n",
      "Train Loader:\n",
      "Batch 1: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 2: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 3: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 4: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 5: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "\n",
      "Valid Loader:\n",
      "Batch 1: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 2: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 3: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 4: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 5: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "\n",
      "Test Loader:\n",
      "Batch 1: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 2: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 3: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 4: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "Batch 5: Videos shape: torch.Size([4, 75, 3, 224, 224]), Labels shape: torch.Size([4, 1])\n",
      "\n",
      "Test Loader Label Distribution:\n",
      "Label 0: 2 samples\n",
      "Label 1: 2 samples\n",
      "Label 2: 2 samples\n",
      "Label 3: 2 samples\n",
      "Label 4: 2 samples\n",
      "Label 5: 2 samples\n",
      "Label 6: 2 samples\n",
      "Label 7: 2 samples\n",
      "Label 8: 2 samples\n",
      "Label 9: 2 samples\n",
      "Label 10: 2 samples\n",
      "Label 11: 2 samples\n",
      "Label 12: 2 samples\n",
      "Label 13: 2 samples\n",
      "Label 14: 2 samples\n",
      "Label 15: 2 samples\n",
      "Label 16: 2 samples\n",
      "Label 17: 2 samples\n",
      "Label 18: 2 samples\n",
      "Label 19: 2 samples\n",
      "Label 20: 2 samples\n",
      "Label 21: 2 samples\n",
      "Label 22: 2 samples\n",
      "Label 23: 2 samples\n",
      "Label 24: 2 samples\n",
      "Label 25: 2 samples\n",
      "Label 26: 2 samples\n",
      "Label 27: 2 samples\n",
      "Label 28: 2 samples\n",
      "Label 29: 2 samples\n",
      "Label 30: 2 samples\n",
      "Label 31: 2 samples\n",
      "Label 32: 2 samples\n",
      "Label 33: 2 samples\n",
      "Label 34: 2 samples\n",
      "Label 35: 2 samples\n",
      "Label 36: 2 samples\n",
      "Label 37: 2 samples\n",
      "Label 38: 2 samples\n",
      "Label 39: 2 samples\n",
      "Label 40: 2 samples\n",
      "Label 41: 2 samples\n",
      "Label 42: 2 samples\n",
      "Label 43: 2 samples\n",
      "Label 44: 2 samples\n",
      "Label 45: 2 samples\n",
      "Label 46: 2 samples\n",
      "Label 47: 2 samples\n",
      "Label 48: 2 samples\n",
      "Label 49: 2 samples\n",
      "Label 50: 2 samples\n",
      "Label 51: 2 samples\n",
      "Label 52: 2 samples\n",
      "Label 53: 2 samples\n",
      "Label 54: 2 samples\n",
      "Label 55: 2 samples\n",
      "Label 56: 2 samples\n",
      "Label 57: 2 samples\n",
      "Label 58: 2 samples\n",
      "Label 59: 2 samples\n",
      "Label 60: 2 samples\n",
      "Label 61: 2 samples\n",
      "Label 62: 2 samples\n",
      "Label 63: 2 samples\n",
      "Label 64: 2 samples\n",
      "Label 65: 2 samples\n",
      "Label 66: 2 samples\n",
      "Label 67: 2 samples\n",
      "Label 68: 2 samples\n",
      "Label 69: 2 samples\n",
      "Label 70: 2 samples\n",
      "Label 71: 2 samples\n",
      "Label 72: 2 samples\n",
      "Label 73: 2 samples\n",
      "Label 74: 2 samples\n",
      "Label 75: 2 samples\n",
      "Label 76: 2 samples\n",
      "Label 77: 2 samples\n",
      "Label 78: 2 samples\n",
      "Label 79: 2 samples\n",
      "Label 80: 2 samples\n",
      "Label 81: 2 samples\n",
      "Label 82: 2 samples\n",
      "Label 83: 2 samples\n",
      "Label 84: 2 samples\n",
      "Label 85: 2 samples\n",
      "Label 86: 2 samples\n",
      "Label 87: 2 samples\n",
      "Label 88: 2 samples\n",
      "Label 89: 2 samples\n",
      "Label 90: 2 samples\n",
      "Label 91: 2 samples\n",
      "Label 92: 2 samples\n",
      "Label 93: 2 samples\n",
      "Label 94: 2 samples\n",
      "Label 95: 2 samples\n",
      "Label 96: 2 samples\n",
      "Label 97: 2 samples\n",
      "Label 98: 2 samples\n",
      "Label 99: 2 samples\n",
      "Label 100: 2 samples\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_avi_files(folder):\n",
    "    \"\"\"\n",
    "    지정된 폴더에서 .avi 파일들을 읽어와 파일명 리스트를 반환합니다.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(folder) if f.lower().endswith('.avi') and os.path.isfile(os.path.join(folder, f))]\n",
    "    return files\n",
    "\n",
    "def extract_label_from_filename(filename):\n",
    "    \"\"\"\n",
    "    파일명에서 1번째 '_'와 2번째 '_' 사이의 문자열을 추출합니다.\n",
    "    반환값: label 문자열 또는 올바른 구분자가 없으면 None\n",
    "    \"\"\"\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    first_us = basename.find('_')\n",
    "    if first_us == -1:\n",
    "        return None\n",
    "    second_us = basename.find('_', first_us + 1)\n",
    "    if second_us == -1:\n",
    "        return None\n",
    "    return basename[first_us+1:second_us]\n",
    "\n",
    "def group_files_by_label(folder, files):\n",
    "    \"\"\"\n",
    "    파일들을 label(파일명에서 1번째 '_'와 2번째 '_' 사이의 문자열) 기준으로 그룹화합니다.\n",
    "    반환값: { label_str: [파일 경로, ...] }\n",
    "    \"\"\"\n",
    "    class_to_files = {}\n",
    "    for file in files:\n",
    "        label_str = extract_label_from_filename(file)\n",
    "        if label_str is None:\n",
    "            print(f\"파일 '{file}'에 올바른 '_' 구분자가 없습니다. 건너뜁니다.\")\n",
    "            continue\n",
    "        file_path = os.path.join(folder, file)\n",
    "        class_to_files.setdefault(label_str, []).append(file_path)\n",
    "    return class_to_files\n",
    "\n",
    "def create_label_mapping(class_to_files):\n",
    "    \"\"\"\n",
    "    그룹화된 파일 딕셔너리에서 고유 label을 추출하여 정렬한 후,\n",
    "    label mapping (문자열 -> 정수)을 생성합니다.\n",
    "    (총 101개의 label이어야 함)\n",
    "    \"\"\"\n",
    "    unique_labels = sorted(class_to_files.keys())\n",
    "    if len(unique_labels) != 101:\n",
    "        print(f\"경고: 고유 label의 개수가 101개가 아닙니다. (총 {len(unique_labels)}개)\")\n",
    "    global_label2idx = { label: idx for idx, label in enumerate(unique_labels) }\n",
    "    print(\"생성된 label mapping (문자열 -> 정수):\")\n",
    "    for label, idx in global_label2idx.items():\n",
    "        print(f\"'{label}' -> {idx}\")\n",
    "    return global_label2idx\n",
    "\n",
    "def sample_videos_for_each_class(class_to_files, target_frames=75, num_samples=10):\n",
    "    \"\"\"\n",
    "    각 클래스마다 num_samples 개의 영상을 선택하고,\n",
    "    각 영상은 최대 target_frames 프레임을 읽어 75프레임 미만이면 제로 패딩을 추가합니다.\n",
    "    반환값: { label_str: [video_frames_list, ...] }\n",
    "      - video_frames_list: 각 영상의 프레임 리스트 (각 프레임은 numpy array)\n",
    "    \"\"\"\n",
    "    class_to_videos = {}\n",
    "    for label_str, file_list in class_to_files.items():\n",
    "        if len(file_list) < num_samples:\n",
    "            print(f\"클래스 '{label_str}'의 파일 개수가 {num_samples}개 미만입니다 (총 {len(file_list)}개). 건너뜁니다.\")\n",
    "            continue\n",
    "        selected_files = random.sample(file_list, num_samples) if len(file_list) > num_samples else file_list\n",
    "        videos = []\n",
    "        for video_path in selected_files:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"영상 '{video_path}' 열기 실패. 건너뜁니다.\")\n",
    "                continue\n",
    "            frames = []\n",
    "            for _ in range(target_frames):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) == 0:\n",
    "                print(f\"영상 '{video_path}'에서 프레임을 하나도 읽지 못했습니다.\")\n",
    "                continue\n",
    "            if len(frames) < target_frames:\n",
    "                pad_frame = np.zeros_like(frames[0])\n",
    "                for _ in range(target_frames - len(frames)):\n",
    "                    frames.append(pad_frame)\n",
    "            if len(frames) > target_frames:\n",
    "                frames = frames[:target_frames]\n",
    "            videos.append(frames)\n",
    "        if len(videos) != num_samples:\n",
    "            print(f\"클래스 '{label_str}'의 {num_samples}개 샘플을 모으지 못했습니다. (모은 샘플 수: {len(videos)})\")\n",
    "            continue\n",
    "        class_to_videos[label_str] = videos\n",
    "    return class_to_videos\n",
    "\n",
    "def split_videos(class_to_videos, split_ratios=(6, 2, 2)):\n",
    "    \"\"\"\n",
    "    각 클래스의 10개 샘플을 split_ratios (train, valid, test) 비율로 분할합니다.\n",
    "    반환값:\n",
    "      - train_list, valid_list, test_list: 각 항목은 (label_str, video_frames_list) 형태\n",
    "    \"\"\"\n",
    "    train_list, valid_list, test_list = [], [], []\n",
    "    for label_str, videos in class_to_videos.items():\n",
    "        random.shuffle(videos)\n",
    "        n_train, n_valid, n_test = split_ratios\n",
    "        train_videos = videos[:n_train]\n",
    "        valid_videos = videos[n_train:n_train+n_valid]\n",
    "        test_videos  = videos[n_train+n_valid:n_train+n_valid+n_test]\n",
    "        for video in train_videos:\n",
    "            train_list.append((label_str, video))\n",
    "        for video in valid_videos:\n",
    "            valid_list.append((label_str, video))\n",
    "        for video in test_videos:\n",
    "            test_list.append((label_str, video))\n",
    "    return train_list, valid_list, test_list\n",
    "\n",
    "def resize_video_frames(video_tensor, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    주어진 영상 텐서(video_tensor, shape: [num_frames, C, H, W])의 모든 프레임을 지정한 크기(size)로 리사이즈합니다.\n",
    "    \"\"\"\n",
    "    return F.interpolate(video_tensor, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_list, label2idx, transform=None):\n",
    "        \"\"\"\n",
    "        video_list: 각 항목이 (label_str, frames(list)) 형태\n",
    "        label2idx: 전역 label mapping (문자열 -> 정수)\n",
    "        transform: 영상 텐서에 적용할 함수 (기본: 모든 프레임을 (224,224)로 리사이즈)\n",
    "        \"\"\"\n",
    "        self.video_list = video_list\n",
    "        self.label2idx = label2idx\n",
    "        self.transform = transform if transform is not None else lambda video: resize_video_frames(video, size=(224, 224))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_str, frames = self.video_list[idx]\n",
    "        # 각 프레임: numpy array (H, W, C) -> torch tensor (C, H, W)\n",
    "        video_tensor = torch.stack([torch.from_numpy(frame).permute(2, 0, 1) for frame in frames])\n",
    "        if self.transform:\n",
    "            video_tensor = self.transform(video_tensor)\n",
    "        # label은 global_label2idx를 통해 정수로 변환하며, (1,) shape의 tensor 반환\n",
    "        label_tensor = torch.tensor([self.label2idx[label_str]], dtype=torch.long)\n",
    "        return video_tensor, label_tensor\n",
    "\n",
    "def create_dataloaders(train_dataset, valid_dataset, test_dataset, batch_size=4):\n",
    "    \"\"\"\n",
    "    주어진 Dataset을 이용하여 DataLoader를 생성합니다.\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def main():\n",
    "    folder = \"/workspace/seq-vision/UCF101\"\n",
    "    print(\"AVI 파일들을 로드하는 중...\")\n",
    "    files = load_avi_files(folder)\n",
    "    print(f\"총 {len(files)}개의 AVI 파일이 발견되었습니다.\")\n",
    "    \n",
    "    print(\"파일들을 label 기준으로 그룹화하는 중...\")\n",
    "    class_to_files = group_files_by_label(folder, files)\n",
    "    \n",
    "    print(\"label mapping 생성 중...\")\n",
    "    global_label2idx = create_label_mapping(class_to_files)\n",
    "    \n",
    "    print(\"각 클래스별로 비디오 샘플 채취 중...\")\n",
    "    class_to_videos = sample_videos_for_each_class(class_to_files, target_frames=75, num_samples=10)\n",
    "    \n",
    "    print(\"비디오 데이터를 train, valid, test로 분할하는 중...\")\n",
    "    train_list, valid_list, test_list = split_videos(class_to_videos, split_ratios=(6, 2, 2))\n",
    "    print(f\"Train samples: {len(train_list)}, Valid samples: {len(valid_list)}, Test samples: {len(test_list)}\")\n",
    "    \n",
    "    print(\"PyTorch Dataset 및 DataLoader 생성 중...\")\n",
    "    train_dataset = VideoDataset(train_list, label2idx=global_label2idx)\n",
    "    valid_dataset = VideoDataset(valid_list, label2idx=global_label2idx)\n",
    "    test_dataset  = VideoDataset(test_list,  label2idx=global_label2idx)\n",
    "    \n",
    "    batch_size = 4\n",
    "    train_loader, valid_loader, test_loader = create_dataloaders(train_dataset, valid_dataset, test_dataset, batch_size)\n",
    "    \n",
    "    print(\"Train Loader:\")\n",
    "    for i, (videos, labels) in enumerate(train_loader):\n",
    "        print(f\"Batch {i+1}: Videos shape: {videos.shape}, Labels shape: {labels.shape}\")\n",
    "        if i == 4:\n",
    "            break\n",
    "\n",
    "    print(\"\\nValid Loader:\")\n",
    "    for i, (videos, labels) in enumerate(valid_loader):\n",
    "        print(f\"Batch {i+1}: Videos shape: {videos.shape}, Labels shape: {labels.shape}\")\n",
    "        if i == 4:\n",
    "            break\n",
    "\n",
    "    print(\"\\nTest Loader:\")\n",
    "    for i, (videos, labels) in enumerate(test_loader):\n",
    "        print(f\"Batch {i+1}: Videos shape: {videos.shape}, Labels shape: {labels.shape}\")\n",
    "        if i == 4:\n",
    "            break\n",
    "\n",
    "    # test_loader 내 label 분포 출력\n",
    "    label_counts = defaultdict(int)\n",
    "    for _, labels in test_loader:\n",
    "        for label in labels:\n",
    "            label_counts[label.item()] += 1\n",
    "\n",
    "    print(\"\\nTest Loader Label Distribution:\")\n",
    "    for label in sorted(label_counts.keys()):\n",
    "        print(f\"Label {label}: {label_counts[label]} samples\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
